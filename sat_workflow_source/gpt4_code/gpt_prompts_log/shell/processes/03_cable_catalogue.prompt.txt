You are an Azure SQL and python expert. 
Convert the following Databricks SQL statement into python code.


Do not value brevity.
Make the code as modular as possible.
Use clean coding principles.
Follow the PEP8 style guide.
Use human readable names.
Choose descriptive and unambiguous names.
Choose pronounceable names.
Choose searchable names.
Never choose any abbreviations or shortened variable names.
Replace magic numbers with named constants.
Define any literals as named constants.
Define and name all lists and arrays separately.
Fully generate all lists, arrays, dictionaries of mappings.
Use the names 'dataframe' instead of 'df' and 'pandas' instead of 'pd'. Do not abbreviate.
Ignore all the comments, which are indicated by -- inside the sql.
Generate an orchestrating function for the component functions. Add an underscore to the beginning of component function names.
Make the name of the main function: create_dataframe_gold_c03_cable_catalogue_sql_01_00
This python function will have a single input parameter called 'input_tables', which will be of type dictionary and will contain the sql tables stored as dataframes keyed upon their sql name (a string). 
To retrieve the dataframes from the dictionary, create string literals for the names of the SQL tables and use these to access the dataframes from the dictionary.


Treat the input files as pandas dataframes and read them in as parameters at the start.

Treat the input columns in different ways, modularise these different ways if possible.
A column will be passed through without any modification.
A columnn will be simply mapped to a column with a new name, sometimes multiple times.
A new columnn will be added with a constant value
A columnn will be mapped to a column using  more complex calculations


Do not generate the enums. Refer to the following enums when using column names.
These are the enum schemas for the input tables:

class DatabaseNames(
        Enum):
    DATABASE_NAME = 'database_name'

class S_CableCatalogue(
        Enum):
    ALLOWUSE = 'allowuse'
    ARMOURED = 'armoured'
    CLASS = 'class'
    COLOUR1 = 'colour1'
    COLOUR2 = 'colour2'
    DATABASE_NAME = 'database_name'
    DESCRIPTION = 'description'
    DRUMLENGTH = 'drumlength'
    EARTH_CORE_SIZE = 'earth_core_size'
    EARTHCORE = 'earthcore'
    GROUPSCR = 'groupscr'
    GROUPTYPE = 'grouptype'
    LINETYPE = 'linetype'
    LINETYPEARROWHEAD = 'linetypearrowhead'
    LINETYPECOLOR = 'linetypecolor'
    LINETYPEWIDTH = 'linetypewidth'
    MANUFACTURER = 'manufacturer'
    MATERIAL = 'material'
    NOOFGROUPS = 'noofgroups'
    OASCR = 'oascr'
    OBJECT_IDENTIFIER = 'object_identifier'
    OD = 'od'
    PARQUET_FILE_RELATIVE_PATH = 'parquet_file_relative_path'
    REMARKS = 'remarks'
    SIZE = 'size'
    VOLTAGE = 'voltage'


class S_CableCatalogueNumber_Master(
        Enum):
    CABLE_OBJECT_IDENTIFIER = 'cable_object_identifier'
    CATALOGUENO = 'catalogueno'
    DATABASE_NAME = 'database_name'
    DESCRIPTION = 'description'
    PARQUET_FILE_RELATIVE_PATH = 'parquet_file_relative_path'


This is the Databricks SQL statement called - 03_Cable_Catalogue_sql_01_00.sql

-- CTE for the join and row number calculation
WITH CTE_CableCatalogue AS (
SELECT C.*
,CM.CatalogueNo
,ROW_NUMBER() OVER(PARTITION BY CM.CatalogueNo ORDER BY CM.Cable_Object_Identifier) AS RNT
FROM sigraph_silver.S_CableCatalogue C
INNER JOIN sigraph_silver.S_CableCatalogueNumber_Master CM 
ON CM.database_name=C.database_name 
AND CM.Cable_Object_Identifier = C.Object_Identifier
WHERE Class IN ('Instrumentation','Inst(Shared)','Elec(Shared)')
AND C.database_name IN (SELECT Database_name FROM VW_Database_names)
)

-- Final SELECT statement
SELECT 
CatalogueNo
,Manufacturer
,Class
,Description
,GroupType
,NoOfGroups
,Armoured
,OAScr
,GroupScr
,EarthCore
,Voltage
,Size
,Earth_Core_Size
,OD
,Material
,Colour1
,Colour2
,AllowUse
,DrumLength
,LineType
,LineTypeColor
,LineTypeWidth
,LineTypeArrowHead
,Remarks
FROM CTE_CableCatalogue
WHERE RNT=1

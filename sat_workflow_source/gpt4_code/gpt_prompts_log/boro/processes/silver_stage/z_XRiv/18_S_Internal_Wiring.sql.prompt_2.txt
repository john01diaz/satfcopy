We need to convert Databricks SQL statements into vanilla python code. 
As a first stage we want to find the general patterns in the SQL statements so we can write the python code is a similar way.
To do this we will translate the Databricks SQL statements into python code.

Where things are not clear please ask for a clarification

General instructions
Can you make the code as modular as possible.
Can you use clean coding principles.
Can you follow the PEP8 style guide.
Can you use human readable names.
Can you choose descriptive and unambiguous names.
Can you choose pronounceable names
Can you choose searchable names
Can you NEVER choose any abbreviations or shortened variable names
Can you replace magic numbers with named constants.

Can you define any literals as named constants
Define and name all lists and arrays separately

Specific instructions

Can you treat  the input files as pandas dataframes and read them in as parameters at the start,
Can you treat the dataframes as immutable - in other words, don't update them.

The input columns can be treated in different ways - modularise these different ways if possible.
sometimes a column will be passed through without any modification.
sometimes a column will be simply mapped to a column with a new name - note that the same column may be mapped several times
sometimes a new column will be added with a constant value
sometimes a column will be mapped to a column using  more complex calculations

Can you make sure you complete all the lists and arrays - don't stop in the middle.

Code all literals as constants

Code all column names as constants - can make all the names lower-case.
Can you prefix all the constant column names with the name of the table in which they come from.
Where a column name in a table is used with different cases, can you firstly advise us and secondly use the case of the first occurence.


use the names 'dataframe' and 'pandas' and .numpy' in full, do not abbreviate. 
give variables meaningful names

------------------


This is the Databricks SQL statement called - 18_S_Internal_Wiring

------------------

"
create or replace temp view Internal_Wiring
as
Select Distinct
 A.database_name
,A.object_identifier 
,A.From_Location as From_Parent_Equipment_No
,'' as From_Compartment
,A.From_Item as From_Equipment
,A.Connection_Type as From_Wire_Link
,A.From_Terminal_Marking as From_Marking
-- If the connection is from Terminal strip and if we are unable to find the side of terminal strip (Which can be decided based on Pin Designation (A is left and B is right)). Then put them under Normal connection
,Case when FROM_dynamic_Class='LC_Component_function' 
      and UPPER(regexp_extract(A.From_Terminal_Marking,'[A-Za-z]+',0)) not in ('AB','CD','EF','GH')
      Then 'Normal'
      Else 'R'
      END as From_Left_Right
,A.To_Location as To_Parent_Equipment_No
,'' as To_Compartment
,A.To_Item as To_Equipment_No
,A.Connection_Type as To_Wire_Link
,A.To_Terminal_Marking as To_Marking
,Case when To_dynamic_Class='LC_Component_function' 
      and UPPER(regexp_extract(A.To_Terminal_Marking,'[A-Za-z]+',0)) not in ('AB','CD','EF','GH')
      Then 'Normal'
      Else 'L'
      END as To_Left_Right 
,DF.Class      
from Sigraph_silver.S_Connection A
Inner join Sigraph_Silver.S_Terminals DF 
On DF.Parent_Equipment_No=Coalesce(A.From_Location,'')
and DF.Equipment_No=A.From_Item 
and DF.Marking=A.From_Terminal_Marking
Inner join Sigraph_Silver.S_Terminals DT 
On DT.Parent_Equipment_No=Coalesce(A.To_Location,'')
and DT.Equipment_No=A.To_Item 
and DT.Marking=A.To_Terminal_Marking
Where A.From_Location=A.To_Location -- Internal wiring logic, both to and from equipment should be same.
and A.From_Location  is not null  and A.To_Location is not null 
"

------------------
Here is the updated code following your instructions, all column names are lower case and prefixes are based on the full table names instead of the alias:

------------------
import pandas
import re

# Constants
PARENT_EQUIPMENT_NO_DEFAULT = ""
DYNAMIC_CLASS_CONDITION = "LC_Component_function"
VALID_MARKINGS = ["AB", "CD", "EF", "GH"]
FROM_LEFT_RIGHT_DEFAULT = "R"
TO_LEFT_RIGHT_DEFAULT = "L"

# Column names constants for s_connection
S_CONNECTION_DATABASE_NAME = "database_name"
S_CONNECTION_OBJECT_IDENTIFIER = "object_identifier"
S_CONNECTION_FROM_LOCATION = "from_location"
S_CONNECTION_FROM_ITEM = "from_item"
S_CONNECTION_CONNECTION_TYPE = "connection_type"
S_CONNECTION_FROM_TERMINAL_MARKING = "from_terminal_marking"
S_CONNECTION_FROM_DYNAMIC_CLASS = "from_dynamic_class"
S_CONNECTION_TO_LOCATION = "to_location"
S_CONNECTION_TO_ITEM = "to_item"
S_CONNECTION_TO_TERMINAL_MARKING = "to_terminal_marking"
S_CONNECTION_TO_DYNAMIC_CLASS = "to_dynamic_class"

# Column names constants for s_terminals
S_TERMINALS_PARENT_EQUIPMENT_NO = "parent_equipment_no"
S_TERMINALS_EQUIPMENT_NO = "equipment_no"
S_TERMINALS_MARKING = "marking"

def create_internal_wiring(dataframe_s_connection, dataframe_s_terminals):
    # Filtering
    filtered_s_connection = dataframe_s_connection[
        (dataframe_s_connection[S_CONNECTION_FROM_LOCATION] == dataframe_s_connection[S_CONNECTION_TO_LOCATION]) &
        dataframe_s_connection[S_CONNECTION_FROM_LOCATION].notna() &
        dataframe_s_connection[S_CONNECTION_TO_LOCATION].notna()
    ]

    # Merging
    dataframe_merged = pandas.merge(
        filtered_s_connection,
        dataframe_s_terminals,
        left_on=[S_CONNECTION_FROM_LOCATION, S_CONNECTION_FROM_ITEM, S_CONNECTION_FROM_TERMINAL_MARKING],
        right_on=[S_TERMINALS_PARENT_EQUIPMENT_NO, S_TERMINALS_EQUIPMENT_NO, S_TERMINALS_MARKING],
        how='inner'
    )
    dataframe_merged = pandas.merge(
        dataframe_merged,
        dataframe_s_terminals,
        left_on=[S_CONNECTION_TO_LOCATION, S_CONNECTION_TO_ITEM, S_CONNECTION_TO_TERMINAL_MARKING],
        right_on=[S_TERMINALS_PARENT_EQUIPMENT_NO, S_TERMINALS_EQUIPMENT_NO, S_TERMINALS_MARKING],
        how='inner',
        suffixes=('_DF', '_DT')
    )

    # Add From_Left_Right and To_Left_Right
    dataframe_merged['from_left_right'] = dataframe_merged.apply(lambda row: FROM_LEFT_RIGHT_DEFAULT if 
        row[S_CONNECTION_FROM_DYNAMIC_CLASS] == DYNAMIC_CLASS_CONDITION and 
        re.findall('[A-Za-z]+', row[S_CONNECTION_FROM_TERMINAL_MARKING].upper())[0] not in VALID_MARKINGS 
        else 'Normal', axis=1)
    dataframe_merged['to_left_right'] = dataframe_merged.apply(lambda row: TO_LEFT_RIGHT_DEFAULT if 
        row[S_CONNECTION_TO_DYNAMIC_CLASS] == DYNAMIC_CLASS_CONDITION and 
        re.findall('[A-Za-z]+', row[S_CONNECTION_TO_TERMINAL_MARKING].upper())[0] not in VALID_MARKINGS 
        else 'Normal', axis=1)

    # Rename the columns
    dataframe_merged = dataframe_merged.rename(columns={
        S_CONNECTION_DATABASE_NAME: 'database_name',
        S_CONNECTION_OBJECT_IDENTIFIER: 'object_identifier',
        S_CONNECTION_FROM_LOCATION: 'from_parent_equipment_no',
        '': 'from_compartment',
        S_CONNECTION_FROM_ITEM: 'from_equipment',
        S_CONNECTION_CONNECTION_TYPE: 'from_wire_link',
        S_CONNECTION_FROM_TERMINAL_MARKING: 'from_marking',
        S_CONNECTION_TO_LOCATION: 'to_parent_equipment_no',
        '': 'to_compartment',
        S_CONNECTION_TO_ITEM: 'to_equipment_no',
        S_CONNECTION_CONNECTION_TYPE: 'to_wire_link',
        S_CONNECTION_TO_TERMINAL_MARKING: 'to_marking',
    })

    # Select distinct rows
    dataframe_internal_wiring = dataframe_merged.drop_duplicates()

    return dataframe_internal_wiring



------------------

Please note that in SQL, a query can return a view with duplicate columns (e.g., A.Connection_Type appears twice in the SQL query). In pandas, however, column names must be unique, so in the conversion, we've used unique names for every column. If you want to keep duplicate columns, you might have to adjust this part according to your needs. Also, the "DF.Class" and "DT.Class" columns are not mapped because their original names in the s_terminals dataframe were not specified.